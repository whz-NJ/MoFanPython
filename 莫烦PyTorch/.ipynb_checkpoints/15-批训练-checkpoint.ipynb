{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d280860",
   "metadata": {},
   "source": [
    "### 要点\n",
    "Torch 中提供了一种帮你整理你的数据结构的好东西, 叫做 DataLoader, 我们能用它来包装自己的数据, 进行批训练. 而且批训练可以有很多种途径, 详情请见 我制作的 训练优化器 动画简介."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9276e5b",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "DataLoader 是 torch 给你用来包装你的数据的工具. 所以你要讲自己的 (numpy array 或其他) 数据形式装换成 Tensor, 然后再放进这个包装器中. 使用 DataLoader 有什么好处呢? 就是他们帮你有效地迭代数据, 举例:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c0b0a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | batch x:  [ 5.  7. 10.  3.  4.] | batch y:  [6. 4. 1. 8. 7.]\n",
      "Epoch:  0 | Step:  1 | batch x:  [2. 1. 8. 9. 6.] | batch y:  [ 9. 10.  3.  2.  5.]\n",
      "Epoch:  1 | Step:  0 | batch x:  [ 4.  6.  7. 10.  8.] | batch y:  [7. 5. 4. 1. 3.]\n",
      "Epoch:  1 | Step:  1 | batch x:  [5. 3. 2. 1. 9.] | batch y:  [ 6.  8.  9. 10.  2.]\n",
      "Epoch:  2 | Step:  0 | batch x:  [ 4.  2.  5.  6. 10.] | batch y:  [7. 9. 6. 5. 1.]\n",
      "Epoch:  2 | Step:  1 | batch x:  [3. 9. 1. 8. 7.] | batch y:  [ 8.  2. 10.  3.  4.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nEpoch:  0 | Step:  0 | batch x:  [ 6.  7.  2.  3.  1.] | batch y:  [  5.   4.   9.   8.  10.]\\nEpoch:  0 | Step:  1 | batch x:  [  9.  10.   4.   8.   5.] | batch y:  [ 2.  1.  7.  3.  6.]\\nEpoch:  1 | Step:  0 | batch x:  [  3.   4.   2.   9.  10.] | batch y:  [ 8.  7.  9.  2.  1.]\\nEpoch:  1 | Step:  1 | batch x:  [ 1.  7.  8.  5.  6.] | batch y:  [ 10.   4.   3.   6.   5.]\\nEpoch:  2 | Step:  0 | batch x:  [ 3.  9.  2.  6.  7.] | batch y:  [ 8.  2.  9.  5.  4.]\\nEpoch:  2 | Step:  1 | batch x:  [ 10.   4.   8.   1.   5.] | batch y:  [  1.   7.   3.  10.   6.]\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.utils.data as Data\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "BATCH_SIZE = 5      # 批训练的数据个数\n",
    "\n",
    "x = torch.linspace(1, 10, 10)       # x data (torch tensor)\n",
    "y = torch.linspace(10, 1, 10)       # y data (torch tensor)\n",
    "\n",
    "# 先转换成 torch 能识别的 Dataset\n",
    "# torch_dataset = Data.TensorDataset(data_tensor=x, target_tensor=y)\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "# 把 dataset 放入 DataLoader\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)\n",
    "    num_workers=2,              # 多线程来读数据\n",
    ")\n",
    "\n",
    "for epoch in range(3):   # 训练所有!整套!数据 3 次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):  # 每一步 loader 释放一小批数据用来学习\n",
    "        # 假设这里就是你训练的地方...\n",
    "\n",
    "        # 打出来一些数据\n",
    "        print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',\n",
    "              batch_x.numpy(), '| batch y: ', batch_y.numpy())\n",
    "\n",
    "\"\"\"\n",
    "Epoch:  0 | Step:  0 | batch x:  [ 6.  7.  2.  3.  1.] | batch y:  [  5.   4.   9.   8.  10.]\n",
    "Epoch:  0 | Step:  1 | batch x:  [  9.  10.   4.   8.   5.] | batch y:  [ 2.  1.  7.  3.  6.]\n",
    "Epoch:  1 | Step:  0 | batch x:  [  3.   4.   2.   9.  10.] | batch y:  [ 8.  7.  9.  2.  1.]\n",
    "Epoch:  1 | Step:  1 | batch x:  [ 1.  7.  8.  5.  6.] | batch y:  [ 10.   4.   3.   6.   5.]\n",
    "Epoch:  2 | Step:  0 | batch x:  [ 3.  9.  2.  6.  7.] | batch y:  [ 8.  2.  9.  5.  4.]\n",
    "Epoch:  2 | Step:  1 | batch x:  [ 10.   4.   8.   1.   5.] | batch y:  [  1.   7.   3.  10.   6.]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195513d2",
   "metadata": {},
   "source": [
    "可以看出, 每步都导出了5个数据进行学习. 然后每个 epoch 的导出数据都是先打乱了以后再导出.\n",
    "\n",
    "真正方便的还不是这点. 如果我们改变一下 BATCH_SIZE = 8, 这样我们就知道, step=0 会导出8个数据, 但是, step=1 时数据库中的数据不够 8个, 这时怎么办呢:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11fc4efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 | Step:  0 | batch x:  [ 4. 10.  9.  8.  7.  6.  1.  2.] | batch y:  [ 7.  1.  2.  3.  4.  5. 10.  9.]\n",
      "Epoch:  0 | Step:  1 | batch x:  [5. 3.] | batch y:  [6. 8.]\n",
      "Epoch:  1 | Step:  0 | batch x:  [9. 8. 4. 6. 5. 3. 7. 2.] | batch y:  [2. 3. 7. 5. 6. 8. 4. 9.]\n",
      "Epoch:  1 | Step:  1 | batch x:  [10.  1.] | batch y:  [ 1. 10.]\n",
      "Epoch:  2 | Step:  0 | batch x:  [ 5.  1.  3.  7.  6. 10.  9.  8.] | batch y:  [ 6. 10.  8.  4.  5.  1.  2.  3.]\n",
      "Epoch:  2 | Step:  1 | batch x:  [2. 4.] | batch y:  [9. 7.]\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8      # 批训练的数据个数\n",
    "\n",
    "x = torch.linspace(1, 10, 10)       # x data (torch tensor)\n",
    "y = torch.linspace(10, 1, 10)       # y data (torch tensor)\n",
    "\n",
    "# 先转换成 torch 能识别的 Dataset\n",
    "# torch_dataset = Data.TensorDataset(data_tensor=x, target_tensor=y)\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "# 把 dataset 放入 DataLoader\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # 要不要打乱数据 (打乱比较好)\n",
    "    num_workers=2,              # 多线程来读数据\n",
    ")\n",
    "\n",
    "for epoch in range(3):   # 训练所有!整套!数据 3 次\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):  # 每一步 loader 释放一小批数据用来学习\n",
    "        # 假设这里就是你训练的地方...\n",
    "\n",
    "        # 打出来一些数据\n",
    "        print('Epoch: ', epoch, '| Step: ', step, '| batch x: ',\n",
    "              batch_x.numpy(), '| batch y: ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b12878",
   "metadata": {},
   "source": [
    "这时, 在 step=1 就只给你返回这个 epoch 中剩下的数据就好了.\n",
    "\n",
    "所以这也就是在我 github 代码 中的每一步的意义啦."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3e312f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
