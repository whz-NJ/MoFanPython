{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89feb498",
   "metadata": {},
   "source": [
    "### 用 Numpy 还是 Torch\n",
    "Torch 自称为神经网络界的 Numpy, 因为他能将 torch 产生的 tensor 放在 GPU 中加速运算 (前提是你有合适的 GPU), 就像 Numpy 会把 array 放在 CPU 中加速运算. 所以神经网络的话, 当然是用 Torch 的 tensor 形式数据最好咯. 就像 Tensorflow 当中的 tensor 一样.\n",
    "\n",
    "当然, 我们对 Numpy 还是爱不释手的, 因为我们太习惯 numpy 的形式了. 不过 torch 看出来我们的喜爱, 他把 torch 做的和 numpy 能很好的兼容. 比如这样就能自由地转换 numpy array 和 torch tensor 了:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d2f5f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "numpy array: [[0 1 2]\n",
      " [3 4 5]] \n",
      "torch tensor: tensor([[0, 1, 2],\n",
      "        [3, 4, 5]], dtype=torch.int32) \n",
      "tensor to array: [[0 1 2]\n",
      " [3 4 5]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np_data = np.arange(6).reshape((2, 3))\n",
    "torch_data = torch.from_numpy(np_data)\n",
    "tensor2array = torch_data.numpy()\n",
    "print(\n",
    "    '\\nnumpy array:', np_data,          # [[0 1 2], [3 4 5]]\n",
    "    '\\ntorch tensor:', torch_data,      #  0  1  2 \\n 3  4  5    [torch.LongTensor of size 2x3]\n",
    "    '\\ntensor to array:', tensor2array, # [[0 1 2], [3 4 5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470f28ee",
   "metadata": {},
   "source": [
    "### Torch 中的数学运算\n",
    "其实 torch 中 tensor 的运算和 numpy array 的如出一辙, 我们就以对比的形式来看. 如果想了解 torch 中其它更多有用的运算符, API就是你要去的地方(http://pytorch.org/docs/torch.html#math-operations )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae6edae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "abs \n",
      "numpy:  [1 2 1 2] \n",
      "torch:  tensor([1., 2., 1., 2.])\n",
      "\n",
      "sin \n",
      "numpy:  [-0.84147098 -0.90929743  0.84147098  0.90929743] \n",
      "torch:  tensor([-0.8415, -0.9093,  0.8415,  0.9093])\n",
      "\n",
      "mean \n",
      "numpy:  0.0 \n",
      "torch:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# abs 绝对值计算\n",
    "data = [-1, -2, 1, 2]\n",
    "tensor = torch.FloatTensor(data)  # 转换成32位浮点 tensor\n",
    "print(\n",
    "    '\\nabs',\n",
    "    '\\nnumpy: ', np.abs(data),          # [1 2 1 2]\n",
    "    '\\ntorch: ', torch.abs(tensor)      # [1 2 1 2]\n",
    ")\n",
    "\n",
    "# sin   三角函数 sin\n",
    "print(\n",
    "    '\\nsin',\n",
    "    '\\nnumpy: ', np.sin(data),      # [-0.84147098 -0.90929743  0.84147098  0.90929743]\n",
    "    '\\ntorch: ', torch.sin(tensor)  # [-0.8415 -0.9093  0.8415  0.9093]\n",
    ")\n",
    "\n",
    "# mean  均值\n",
    "print(\n",
    "    '\\nmean',\n",
    "    '\\nnumpy: ', np.mean(data),         # 0.0\n",
    "    '\\ntorch: ', torch.mean(tensor)     # 0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b0ce1d",
   "metadata": {},
   "source": [
    "除了简单的计算, 矩阵运算才是神经网络中最重要的部分. 所以我们展示下矩阵的乘法. 注意一下包含了一个 numpy 中可行, 但是 torch 中不可行的方式."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af465483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "matrix multiplication (matmul) \n",
      "numpy:  [[ 7 10]\n",
      " [15 22]] \n",
      "torch:  tensor([[ 7., 10.],\n",
      "        [15., 22.]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-07888e365e3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;34m'\\nmatrix multiplication (dot)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;34m'\\nnumpy: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m        \u001b[1;31m# [[7, 10], [15, 22]] 在numpy 中可行\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;34m'\\ntorch: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# torch 会转换成 [1,2,3,4].dot([1,2,3,4) = 30.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "# matrix multiplication 矩阵点乘\n",
    "data = [[1,2], [3,4]]\n",
    "tensor = torch.FloatTensor(data)  # 转换成32位浮点 tensor\n",
    "# correct method\n",
    "print(\n",
    "    '\\nmatrix multiplication (matmul)',\n",
    "    '\\nnumpy: ', np.matmul(data, data),     # [[7, 10], [15, 22]]\n",
    "    '\\ntorch: ', torch.mm(tensor, tensor)   # [[7, 10], [15, 22]]\n",
    ")\n",
    "\n",
    "# !!!!  下面是错误的方法 !!!!\n",
    "data = np.array(data)\n",
    "print(\n",
    "    '\\nmatrix multiplication (dot)',\n",
    "    '\\nnumpy: ', data.dot(data),        # [[7, 10], [15, 22]] 在numpy 中可行\n",
    "    '\\ntorch: ', tensor.dot(tensor)     # torch 会转换成 [1,2,3,4].dot([1,2,3,4) = 30.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd950f",
   "metadata": {},
   "source": [
    "新版本中(>=0.3.0), 关于 tensor.dot() 有了新的改变, 它只能针对于一维的数组. 所以上面的有所改变."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae436ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "dot: Expected 1-D argument self, but got 2-D",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-699a1350cc35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m     \u001b[1;31m# torch 会转换成 [1,2,3,4].dot([1,2,3,4) = 30.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 变为\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: dot: Expected 1-D argument self, but got 2-D"
     ]
    }
   ],
   "source": [
    "tensor.dot(tensor)     # torch 会转换成 [1,2,3,4].dot([1,2,3,4) = 30.0\n",
    "\n",
    "# 变为\n",
    "torch.dot(tensor.dot(tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bb25b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
